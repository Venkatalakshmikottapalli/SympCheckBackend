{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the libraries\n",
    "import pandas as pd\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split, cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comment**: Imported the required libraries to perform the tasks below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diseases</th>\n",
       "      <th>symptoms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>panic disorder</td>\n",
       "      <td>anxiety and nervousness ,shortness of breath ,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>panic disorder</td>\n",
       "      <td>shortness of breath ,depressive or psychotic s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>panic disorder</td>\n",
       "      <td>anxiety and nervousness ,depression ,shortness...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>panic disorder</td>\n",
       "      <td>anxiety and nervousness ,depressive or psychot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>panic disorder</td>\n",
       "      <td>anxiety and nervousness ,depression ,insomnia ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         diseases                                           symptoms\n",
       "0  panic disorder  anxiety and nervousness ,shortness of breath ,...\n",
       "1  panic disorder  shortness of breath ,depressive or psychotic s...\n",
       "2  panic disorder  anxiety and nervousness ,depression ,shortness...\n",
       "3  panic disorder  anxiety and nervousness ,depressive or psychot...\n",
       "4  panic disorder  anxiety and nervousness ,depression ,insomnia ..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataframe from csv\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/ktxdev/symp-check/main/backend/data/processed/symptoms_disease.csv')\n",
    "# Display dataframe\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comment**: In this step, we are loading the  dataset from a CSV file, allowing us to explore the data structure and contents of the file as you can see in the output. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the data into a training and testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Spliting the data for test and train\n",
    "train, test = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "# assigning the train and test variables\n",
    "X_train = train['symptoms']\n",
    "X_test = test['symptoms']\n",
    "y_train = train['diseases'] \n",
    "y_test = test['diseases']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comment**: Now, in the above code cell we are spliting the data into training and testing sets, to ensure a balanced approach to model evaluation by separating features (X) and labels (y).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(395112, 340)\n",
      "(98778, 340)\n"
     ]
    }
   ],
   "source": [
    "# Vectorize the text data\n",
    "tfidf_vectorizer = TfidfVectorizer(min_df=10)\n",
    "# Fit the training data\n",
    "X_train_bow = tfidf_vectorizer.fit_transform(X_train)\n",
    "# Transform the test data\n",
    "X_test_bow = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "print(X_train_bow.shape)\n",
    "print(X_test_bow.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comment**: We used TfidfVectorizer to vectorize the text data and fit the training data and transform the test data. This results in output shapes of (395112, 340) for training and (98778, 340) for testing, representing the number of documents and features, respectively.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection and Cross Validation\n",
    "### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/nlp_env/lib/python3.10/site-packages/sklearn/model_selection/_split.py:776: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.86428002, 0.86462169, 0.86120321, 0.86363291, 0.86383539])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the SVM model\n",
    "svm_model = SVC(kernel='linear')\n",
    "svm_model.fit(X_train_bow, y_train)\n",
    "# Perform cross-validation\n",
    "svm_model_acc = cross_val_score(estimator=svm_model, X = X_train_bow, y = y_train, cv = 5, n_jobs = -1)\n",
    "# Return the array of accuracy scores for each fold\n",
    "svm_model_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comment**: We applied a Support Vector Machine (SVM) with a linear kernel to the vectorized data and assessed its performance through cross-validation. The accuracy scores from cross-validation are [0.86420802, 0.86462169, 0.86102321, 0.86363291, 0.86383539]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/nlp_env/lib/python3.10/site-packages/sklearn/model_selection/_split.py:776: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.86234387, 0.86164787, 0.85943155, 0.86127914, 0.86165878])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize Logistic Regression model\n",
    "lg_model = LogisticRegression()\n",
    "# Fit the model on the training data\n",
    "lg_model.fit(X_train_bow, y_train)\n",
    "# Perform cross-validation\n",
    "lg_model_acc = cross_val_score(estimator=lg_model, X = X_train_bow, y = y_train, cv = 5, n_jobs = -1)\n",
    "# Return the array of accuracy scores for each fold\n",
    "lg_model_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comment**: We trained a Logistic Regression model on the vectorized data and evaluated its performance using cross-validation. The model demonstrated consistent accuracy scores of [0.86234387, 0.86164787, 0.85943155, 0.86127914, 0.86165878] across different folds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/nlp_env/lib/python3.10/site-packages/sklearn/model_selection/_split.py:776: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.83662984, 0.83680701, 0.83412214, 0.8357546 , 0.83476753])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize Decision Tree Classifier model\n",
    "dtc_model = DecisionTreeClassifier()\n",
    "# Fit the model on the training data\n",
    "dtc_model.fit(X_train_bow, y_train)\n",
    "# Perform cross-validation\n",
    "dtc_model_acc = cross_val_score(estimator=dtc_model, X=X_train_bow, y=y_train, cv=5, n_jobs=-1)\n",
    "# Return the array of accuracy scores for each fold\n",
    "dtc_model_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comment**: We have trained a Decision Tree Classifier on the vectorized data and evaluated its accuracy using cross-validation. The accuracy scores obtained from the cross-validation are as follows: 0.83662984, 0.83680701, 0.83412214, 0.8357546, 0.83476753."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/nlp_env/lib/python3.10/site-packages/sklearn/model_selection/_split.py:776: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.79803348, 0.79622388, 0.79699324, 0.79581635, 0.79634785])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize Multinomial Naive Bayes model\n",
    "mnb_model = MultinomialNB()\n",
    "# Fit the model on the training data\n",
    "mnb_model.fit(X_train_bow, y_train)\n",
    "# Perform cross-validation\n",
    "mnb_model_acc = cross_val_score(estimator=mnb_model, X=X_train_bow, y=y_train, cv=5, n_jobs=-1)\n",
    "# Return the array of scores for each fold\n",
    "mnb_model_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comment**: We utilize a Multinomial Naive Bayes model on the vectorized data and assessing its performance using cross-validation. The accuracy scores from cross-validation are as follows: 0.79803348, 0.79622388, 0.79699324, 0.79581635, and 0.79634758. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vector Machine Accuracy:\t 0.8644839944117111\n",
      "Decision Tree Classifier Accuracy:\t 0.841381684180688\n",
      "Multinomial Naive Bayes Accurracy:\t 0.8022029196784709\n",
      "Logistic Regression Accuracy:\t\t 0.863066674765636\n"
     ]
    }
   ],
   "source": [
    "# Evaluate Support Vector Machine model accuracy on test set\n",
    "print(\"Support Vector Machine Accuracy:\\t\", svm_model.score(X_test_bow, y_test))\n",
    "\n",
    "# Evaluate Decision Tree Classifier accuracy on test set\n",
    "print(\"Decision Tree Classifier Accuracy:\\t\", dtc_model.score(X_test_bow, y_test))\n",
    "\n",
    "# Evaluate Multinomial Naive Bayes accuracy on test set\n",
    "# Note: .toarray() is used to convert sparse matrix to dense array, which MNB requires\n",
    "print(\"Multinomial Naive Bayes Accurracy:\\t\", mnb_model.score(X_test_bow.toarray(), y_test))\n",
    "\n",
    "# Evaluate Logistic Regression accuracy on test set\n",
    "print(\"Logistic Regression Accuracy:\\t\\t\", lg_model.score(X_test_bow, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comment**: We have checked how well the models perform on the test data. The Support Vector Machine got an accuracy of 86.44%, the Decision Tree Classifier scored 84.12%, the Multinomial Naive Bayes reached 80.22%, and the Logistic Regression model got 86.30%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/nlp_env/lib/python3.10/site-packages/sklearn/model_selection/_split.py:776: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params:\t {'C': 10, 'solver': 'liblinear'}\n",
      "Accurracy:\t\t 0.8639373139767964\n"
     ]
    }
   ],
   "source": [
    "# Define hyperparameters to search\n",
    "params = {'C': [0.1, 1, 10], 'solver': ['liblinear']}\n",
    "\n",
    "# Initialize Logistic Regression model\n",
    "lg_model = LogisticRegression()\n",
    "lg_model.fit(X_train_bow, y_train)\n",
    "\n",
    "# Setting up GridSearchCV\n",
    "gscv = GridSearchCV(lg_model, params, cv=5, n_jobs=-1)\n",
    "# Perform grid search on training data\n",
    "gscv.fit(X_train_bow, y_train)\n",
    "\n",
    "# Print best parameters found\n",
    "print(\"Best Params:\\t\", gscv.best_params_)\n",
    "\n",
    "# Print accuracy on test se\n",
    "print(\"Accurracy:\\t\\t\", gscv.score(X_test_bow, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comment**: We adjusted the Logistic Regression model by testing different settings for the parameters. The best settings found were {'C': 10, 'solver': 'liblinear'}, which improved the model's accuracy to 86.39% on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
